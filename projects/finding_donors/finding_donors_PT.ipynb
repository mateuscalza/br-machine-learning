{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizado Supervisionado\n",
    "## Projeto: Encontrando doadores para a *CharityML*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seja bem-vindo ao segundo projeto do Nanodegree Engenheiro de Machine Learning! Neste notebook, você receberá alguns códigos de exemplo e será seu trabalho implementar as funcionalidades adicionais necessárias para a conclusão do projeto. As seções cujo cabeçalho começa com **'Implementação'** indicam que o bloco de código posterior requer funcionalidades adicionais que você deve desenvolver. Para cada parte do projeto serão fornecidas instruções e as diretrizes da implementação estarão marcadas no bloco de código com uma expressão `'TODO'`. \n",
    "Por favor, leia cuidadosamente as instruções!\n",
    "\n",
    "Além de implementações de código, você terá de responder questões relacionadas ao projeto e à sua implementação. Cada seção onde você responderá uma questão terá um cabeçalho com o termo **'Questão X'**. Leia com atenção as questões e forneça respostas completas nas caixas de texto que começam com o termo **'Resposta:'**. A submissão do seu projeto será avaliada baseada nas suas resostas para cada uma das questões além das implementações que você disponibilizar.\n",
    "\n",
    "**Versão do Python escolhida: 3.7**\n",
    "\n",
    ">**Nota:** Por favor, especifique QUAL A VERSÃO DO PYTHON utilizada por você para a submissão deste notebook. As células \"Code\" e \"Markdown\" podem ser executadas utilizando o atalho do teclado **Shift + Enter**. Além disso, as células \"Markdown\" podem ser editadas clicando-se duas vezes na célula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando\n",
    "\n",
    "Neste projeto, você utilizará diversos algoritmos de aprendizado supervisionado para modelar com precisão a remuneração de indivíduos utilizando dados coletados no censo americano de 1994. Você escolherá o algoritmo mais adequado através dos resultados preliminares e irá otimizá-lo para modelagem dos dados. O seu objetivo com esta implementação é construir um modelo que pode predizer com precisão se um indivíduo possui uma remuneração superior a $50,000. Este tipo de tarefa pode surgir em organizações sem fins lucrativos que sobrevivem de doações. Entender a remuneração de um indivíduo pode ajudar a organização o montante mais adequado para uma solicitação de doação, ou ainda se eles realmente deveriam entrar em contato com a pessoa. Enquanto pode ser uma tarefa difícil determinar a faixa de renda de uma pesssoa de maneira direta, nós podemos inferir estes valores através de outros recursos disponíveis publicamente. \n",
    "\n",
    "O conjunto de dados para este projeto se origina do [Repositório de Machine Learning UCI](https://archive.ics.uci.edu/ml/datasets/Census+Income) e foi cedido por Ron Kohavi e Barry Becker, após a sua publicação no artigo _\"Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"_. Você pode encontrar o artigo de Ron Kohavi [online](https://www.aaai.org/Papers/KDD/1996/KDD96-033.pdf). Os dados que investigaremos aqui possuem algumas pequenas modificações se comparados com os dados originais, como por exemplo a remoção da funcionalidade `'fnlwgt'` e a remoção de registros inconsistentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Explorando os dados\n",
    "Execute a célula de código abaixo para carregas as bibliotecas Python necessárias e carregas os dados do censo. Perceba que a última coluna deste cojunto de dados, `'income'`, será o rótulo do nosso alvo (se um indivíduo possui remuneração igual ou maior do que $50,000 anualmente). Todas as outras colunas são dados de cada indívduo na base de dados do censo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass education_level  education-num  marital-status  \\\n",
       "0   39   State-gov       Bachelors           13.0   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country income  \n",
       "0            40.0   United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importe as bibliotecas necessárias para o projeto.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Permite a utilização da função display() para DataFrames.\n",
    "\n",
    "# Importação da biblioteca de visualização visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "# Exibição amigável para notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Carregando os dados do Censo\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "\n",
    "# Sucesso - Exibindo o primeiro registro\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Explorando os Dados\n",
    "\n",
    "Uma investigação superficial da massa de dados determinará quantos indivíduos se enquadram em cada grupo e nos dirá sobre o percentual destes indivúdos com remuneração anual superior à \\$50,000. No código abaixo, você precisará calcular o seguinte:\n",
    "- O número total de registros, `'n_records'`\n",
    "- O número de indivíduos com remuneração anual superior à \\$50,000, `'n_greater_50k'`.\n",
    "- O número de indivíduos com remuneração anual até \\$50,000, `'n_at_most_50k'`.\n",
    "- O percentual de indivíduos com remuneração anual superior à \\$50,000, `'greater_percent'`.\n",
    "\n",
    "** DICA: ** Você pode precisar olhar a tabela acima para entender como os registros da coluna `'income'` estão formatados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 45222\n",
      "Individuals making more than $50,000: 11208\n",
      "Individuals making at most $50,000: 34014\n",
      "Percentage of individuals making more than $50,000: 24.78%\n"
     ]
    }
   ],
   "source": [
    "# Número total de registros.\n",
    "n_records = data.index.size\n",
    "\n",
    "# Número de registros com remuneração anual superior à $50,000\n",
    "n_greater_50k = data[data['income']=='>50K'].index.size\n",
    "\n",
    "# O número de registros com remuneração anual até $50,000\n",
    "n_at_most_50k = n_records - data[data['income']=='>50K'].index.size\n",
    "\n",
    "# O percentual de indivíduos com remuneração anual superior à $50,000\n",
    "greater_percent = n_greater_50k / n_records * 100\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50,000: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Explorando as colunas **\n",
    "* **age**: contínuo. \n",
    "* **workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num**: contínuo. \n",
    "* **marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race**: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other. \n",
    "* **sex**: Female, Male. \n",
    "* **capital-gain**: contínuo. \n",
    "* **capital-loss**: contínuo. \n",
    "* **hours-per-week**: contínuo. \n",
    "* **native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparando os dados\n",
    "Antes de que os dados possam ser utilizados como input para algoritmos de machine learning, muitas vezes eles precisam ser tratados, formatados e reestruturados — este processo é conhecido como **pré-processamento**. Felizmente neste conjunto de dados não existem registros inconsistentes para tratamento, porém algumas colunas precisam ser ajustadas. Este pré-processamento pode ajudar muito com o resultado e poder de predição de quase todos os algoritmos de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os principais desvios das colunas contínuas\n",
    "Um conjunto de dados pode conter ao menos uma coluna onde os valores tendem a se próximar para um único número, mas também podem conter registros com o mesmo atributo contendo um valor muito maior ou muito menor do que esta tendência. Algoritmos podem ser sensíveis para estes casos de distribuição de valores e este fator pode prejudicar sua performance se a distribuição não estiver normalizada de maneira adequada. Com o conjunto de dados do censo, dois atributos se encaixam nesta descrição: '`capital-gain'` e `'capital-loss'`.\n",
    "\n",
    "Execute o código da célula abaixo para plotar um histograma destes dois atributos. Repare na distribuição destes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dividindo os dados entre features e coluna alvo\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)\n",
    "\n",
    "# Visualizando os principais desvios das colunas contínuas entre os dados\n",
    "vs.distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para atributos com distribuição muito distorcida, tais como `'capital-gain'` e `'capital-loss'`, é uma prática comum aplicar uma <a href=\"https://en.wikipedia.org/wiki/Data_transformation_(statistics)\">transformação logarítmica</a> nos dados para que os valores muito grandes e muito pequenos não afetem a performance do algoritmo de aprendizado. Usar a transformação logarítmica reduz significativamente os limites dos valores afetados pelos outliers (valores muito grandes ou muito pequenos). Deve-se tomar cuidado ao aplicar esta transformação, poir o logaritmo de `0` é indefinido, portanto temos que incrementar os valores em uma pequena quantia acima de `0` para aplicar o logaritmo adequadamente.\n",
    "\n",
    "Execute o código da célula abaixo para realizar a transformação nos dados e visualizar os resultados. De novo, note os valores limite e como os valores estão distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicando a transformação de log nos registros distorcidos.\n",
    "skewed = ['capital-gain', 'capital-loss']\n",
    "features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Visualizando as novas distribuições após a transformação.\n",
    "vs.distribution(features_log_transformed, transformed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando atributos numéricos\n",
    "Além das transformações em atributos distorcidos, é uma boa prática comum realizar algum tipo de adaptação de escala nos atributos numéricos. Ajustar a escala nos dados não modifica o formato da distribuição de cada coluna (tais como `'capital-gain'` ou `'capital-loss'` acima); no entanto, a normalização garante que cada atributo será tratado com o mesmo peso durante a aplicação de aprendizado supervisionado. Note que uma vez aplicada a escala, a observação dos dados não terá o significado original, como exemplificado abaixo.\n",
    "\n",
    "Execute o código da célula abaixo para normalizar cada atributo numérico, nós usaremos ara isso a [`sklearn.preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calza/Library/Python/3.7/lib/python/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education_level</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.953584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass education_level  education-num  \\\n",
       "0  0.301370          State-gov       Bachelors       0.800000   \n",
       "1  0.452055   Self-emp-not-inc       Bachelors       0.800000   \n",
       "2  0.287671            Private         HS-grad       0.533333   \n",
       "3  0.493151            Private            11th       0.400000   \n",
       "4  0.150685            Private       Bachelors       0.800000   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0      0.953584           0.0        0.397959   United-States  \n",
       "1      0.000000           0.0        0.122449   United-States  \n",
       "2      0.000000           0.0        0.397959   United-States  \n",
       "3      0.000000           0.0        0.397959   United-States  \n",
       "4      0.000000           0.0        0.397959            Cuba  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Inicializando um aplicador de escala e aplicando em seguida aos atributos\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Exibindo um exemplo de registro com a escala aplicada\n",
    "display(features_log_minmax_transform.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Pré-processamento dos dados\n",
    "\n",
    "A partir da tabela em **Explorando os dados** acima, nós podemos observar que existem diversos atributos não-numéricos para cada registro. Usualmente, algoritmos de aprendizado esperam que os inputs sejam numéricos, o que requer que os atributos não numéricos (chamados de *variáveis de categoria*) sejam convertidos. Uma maneira popular de converter as variáveis de categoria é utilizar a estratégia **one-hot encoding**. Esta estratégia cria uma variável para cada categoria possível de cada atributo não numérico. Por exemplo, assuma que `algumAtributo` possuí três valores possíveis: `A`, `B`, ou `C`. Nós então transformamos este atributo em três novos atributos: `algumAtributo_A`, `algumAtributo_B` e `algumAtributo_C`.\n",
    "\n",
    "\n",
    "|   | algumAtributo |                    | algumAtributo_A | algumAtributo_B | algumAtributo_C |\n",
    "| :-: | :-: |                            | :-: | :-: | :-: |\n",
    "| 0 |  B  |  | 0 | 1 | 0 |\n",
    "| 1 |  C  | ----> one-hot encode ----> | 0 | 0 | 1 |\n",
    "| 2 |  A  |  | 1 | 0 | 0 |\n",
    "\n",
    "Além disso, assim como os atributos não-numéricos, precisaremos converter a coluna alvo não-numérica, `'income'`, para valores numéricos para que o algoritmo de aprendizado funcione. Uma vez que só existem duas categorias possíveis para esta coluna (\"<=50K\" e \">50K\"), nós podemos evitar a utilização do one-hot encoding e simplesmente transformar estas duas categorias para `0` e `1`, respectivamente. No trecho de código abaixo, você precisará implementar o seguinte:\n",
    " - Utilizar [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para realizar o one-hot encoding nos dados da `'features_log_minmax_transform'`.\n",
    " - Converter a coluna alvo `'income_raw'` para re.\n",
    "   - Transforme os registros com \"<=50K\" para `0` e os registros com \">50K\" para `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding nos dados em 'features_log_minmax_transform' utilizando pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "\n",
    "# Encode da coluna 'income_raw' para valores numéricos\n",
    "income = income_raw.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# Número de colunas depois do one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embaralhar e dividir os dados\n",
    "Agora todas as _variáveis de categoria_ foram convertidas em atributos numéricos e todos os atributos numéricos foram normalizados. Como sempre, nós agora dividiremos os dados entre conjuntos de treinamento e de teste. 80% dos dados serão utilizados para treinamento e 20% para teste.\n",
    "\n",
    "Execute o código da célula abaixo para realizar divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 36177 samples.\n",
      "Testing set has 9045 samples.\n"
     ]
    }
   ],
   "source": [
    "# Importar train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os 'atributos' e 'income' entre conjuntos de treinamento e de testes.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_final, \n",
    "                                                    income, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Avaliando a performance do modelo\n",
    "Nesta seção nós investigaremos quatro algoritmos diferentes e determinaremos qual deles é melhor para a modelagem dos dados. Três destes algoritmos serão algoritmos de aprendizado supervisionado de sua escolha e o quarto algoritmo é conhecido como *naive predictor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas e o Naive predictor\n",
    "\n",
    "*CharityML*, equpada com sua pesquisa, sabe que os indivíduos que fazem mais do que \\$50,000 possuem maior probabilidade de doar para a sua campanha de caridade. Por conta disto, a *CharityML* está particularmente interessada em predizer com acurácia quais indivíduos possuem remuneração acima de \\$50,000. Parece que utilizar **acurácia (accuracy)** como uma métrica para avaliar a performance de um modelo é um parâmetro adequado. Além disso, identificar alguém que *não possui* remuneração acima de \\$50,000 como alguém que recebe acima deste valor seria ruim para a *CharityML*, uma vez que eles estão procurando por indivíduos que desejam doar. Com isso, a habilidade do modelo em predizer com precisão aqueles que possuem a remuneração acima dos \\$50,000 é *mais importante* do que a habilidade de realizar o **recall** destes indivíduos. Nós podemos utilizar a fórmula **F-beta score** como uma métrica que considera ambos: precision e recall.\n",
    "\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "Em particular, quando $\\beta = 0.5$, maior ênfase é atribuída para a variável precision. Isso é chamado de **F$_{0.5}$ score** (ou F-score, simplificando).\n",
    "\n",
    "Analisando a distribuição de classes (aqueles que possuem remuneração até \\$50,000 e aqueles que possuem remuneração superior), fica claro que a maioria dos indivíduos não possui remuneração acima de \\$50,000. Isto pode ter grande impacto na **acurácia (accuracy)**, uma vez que nós poderíamos simplesmente dizer *\"Esta pessoa não possui remuneração acima de \\$50,000\"* e estar certos em boa parte das vezes, sem ao menos olhar os dados! Fazer este tipo de afirmação seria chamado de **naive**, uma vez que não consideramos nenhuma informação para balisar este argumento. É sempre importante considerar a *naive prediction* para seu conjunto de dados, para ajudar a estabelecer um benchmark para análise da performance dos modelos. Com isso, sabemos que utilizar a naive prediction não traria resultado algum: Se a predição apontasse que todas as pessoas possuem remuneração inferior à \\$50,000, a *CharityML* não identificaria ninguém como potencial doador. \n",
    "\n",
    "\n",
    "\n",
    "#### Nota: Revisando: accuracy, precision e recall\n",
    "\n",
    "** Accuracy ** mede com que frequência o classificador faz a predição correta. É a proporção entre o número de predições corretas e o número total de predições (o número de registros testados).\n",
    "\n",
    "** Precision ** informa qual a proporção de mensagens classificamos como spam eram realmente spam. Ou seja, é a proporção de verdadeiros positivos (mensagens classificadas como spam que eram realmente spam) sobre todos os positivos (todas as palavras classificadas como spam, independente se a classificação estava correta), em outras palavras, é a proporção\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso positivos)]`\n",
    "\n",
    "** Recall(sensibilidade)** nos informa qual a proporção das mensagens que eram spam que foram corretamente classificadas como spam. É a proporção entre os verdadeiros positivos (classificados como spam, que realmente eram spam) sobre todas as palavras que realmente eram spam. Em outras palavras, é a proporção entre\n",
    "\n",
    "`[Verdadeiros positivos/(Verdadeiros positivos + Falso negativos)]`\n",
    "\n",
    "Para problemas de classificação distorcidos em suas distribuições, como no nosso caso, por exemplo, se tivéssemos 100 mensagens de texto e apenas 2 fossem spam e todas as outras não fossem, a \"accuracy\" por si só não seria uma métrica tão boa. Nós poderiamos classificar 90 mensagens como \"não-spam\" (incluindo as 2 que eram spam mas que teriam sido classificadas como não-spam e, por tanto, seriam falso negativas.) e 10 mensagens como spam (todas as 10 falso positivas) e ainda assim teriamos uma boa pontuação de accuracy. Para estess casos, precision e recall são muito úteis. Estas duas métricas podem ser combinadas para resgatar o F1 score, que é calculado através da média(harmônica) dos valores de precision e de recall. Este score pode variar entre 0 e 1, sendo 1 o melhor resultado possível para o F1 score (consideramos a média harmônica pois estamos lidando com proporções)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Performance do Naive Predictor\n",
    "* Se escolhessemos um modelo que sempre prediz que um indivíduo possui remuneração acima de $50,000, qual seria a accuracy e o F-score considerando este conjunto de dados? Você deverá utilizar o código da célula abaixo e atribuir os seus resultados para as variáveis `'accuracy'` e `'fscore'` que serão usadas posteriormente.\n",
    "\n",
    "** Por favor, note ** que o propósito ao gerar um naive predictor é simplesmente exibir como um modelo sem nenhuma inteligência se comportaria. No mundo real, idealmente o seu modelo de base será o resultado de um modelo anterior ou poderia ser baseado em um paper no qual você se basearia para melhorar. Quando não houver qualquer benchmark de modelo, utilizar um naive predictor será melhor do que uma escolha aleatória.\n",
    "\n",
    "** DICA: ** \n",
    "\n",
    "* Quando temos um modelo que sempre prediz '1' (e.x o indivíduo possui remuneração superior à 50k) então nosso modelo não terá Verdadeiros Negativos ou Falso Negativos, pois nós não estaremos afirmando que qualquer dos valores é negativo (ou '0') durante a predição. Com isso, nossa accuracy neste caso se torna o mesmo valor da precision (Verdadeiros positivos/ (Verdadeiros positivos + Falso positivos)) pois cada predição que fizemos com o valor '1' que deveria ter o valor '0' se torna um falso positivo; nosso denominador neste caso é o número total de registros.\n",
    "* Nossa pontuação de Recall(Verdadeiros positivos/(Verdadeiros Positivos + Falsos negativos)) será 1 pois não teremos Falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.2478, F-score: 0.2917]\n"
     ]
    }
   ],
   "source": [
    "# Contando pois este é o caso \"naive\". Note que 'income' são os dados 'income_raw' convertidos para valores numéricos durante o passo de pré-processamento de dados.\n",
    "TP = np.sum(income)\n",
    "\n",
    "# Específico para o caso naive\n",
    "FP = income.count() - TP\n",
    "\n",
    "# Sem predições negativas para o caso naive\n",
    "TN = 0\n",
    "\n",
    "# Sem predições negativas para o caso naive\n",
    "FN = 0\n",
    "\n",
    "# Calcular accuracy, precision e recall\n",
    "accuracy = TP / (TP + FP)\n",
    "recall = TP / (TP + 0)\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# Calcular o F-score utilizando a fórmula acima para o beta = 0.5 e os valores corretos de precision e recall.\n",
    "beta = 0.5\n",
    "fscore = (1 + beta ** 2) * (precision * recall) / (beta ** 2 * precision + recall)\n",
    "\n",
    "# Exibir os resultados \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelos de Aprendizado Supervisionado\n",
    "**Estes são alguns dos modelos de aprendizado supervisionado disponíveis em** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees (Árvores de decisão)\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação do Modelo\n",
    "Liste três dos modelos de aprendizado supervisionado acima que são apropriados para este problema que você irá testar nos dados do censo. Para cada modelo escolhido\n",
    "\n",
    "- Descreva uma situação do mundo real onde este modelo pode ser utilizado. \n",
    "- Quais são as vantagens da utilização deste modelo; quando ele performa bem?\n",
    "- Quais são as fraquesas do modelo; quando ele performa mal?\n",
    "- O que torna este modelo um bom candidato para o problema, considerando o que você sabe sobre o conjunto de dados?\n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Estruture sua resposta no mesmo formato acima^, com 4 partes para cada um dos modelos que você escolher. Por favor, inclua referências em cada uma das respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**\n",
    "\n",
    "#### Máquinas de Suporte Vetorial - SVM\n",
    "\n",
    "* Podem ser usadas para catalogar reservas indígenas usando imagens de satélite, com o apoio de filtros de visão computacional. Já que as SVMs podem usar Kernel Polinomial para formar curvas e demarcar estes territórios.\n",
    "* Como vantagem temos sua flexibilidade para ajustes. Usando por exemplo o parâmetro C para manipular a margem e o gama (presente no sigma) na fórmula gaussiana para evitar sobreajuste. As SVMs funcionam bem com dados que disponham de várias dimensões.\n",
    "* Como desvantagem, tanta flexibilidade de ajuste pode resultar em configurações erradas, que causam overfitting. Além de que envolve equações complexas e difíceis de compreender, o que pode dificultar o debugging e a manutenção.\n",
    "* É um bom candidato por ser adequado para o número de amostras do dataset, suportar classificação e ter boas opções para ajustes.\n",
    "\n",
    "Conforme visto no Nanodegree e no artigo https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/ de 2015, atualizado em 2017, do autor Sunil Ray.\n",
    "\n",
    "#### Árvores de Decisão\n",
    "\n",
    "* Podem ser usadas para melhorar a experiência do usuário em um e-commerce, algumas características do usuário para oferecer produtos mais relevantes.\n",
    "* Dentre as vantagens, o modelo é ótimo para o entendimento de quem está dando manutenção. Possibilita uma boa visualização de dados, conforme exemplifica o artigo https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176 de Russel (2017). O modelo dispõe de uma performance incrível, tanto para treinamento quanto predição.\n",
    "* A desvantagem é que se a grande parte das colunas se provarem importantes, talvez tenha que ser evoluido para uma Floresta Aleatória. \n",
    "* Por causa da simplicidade do modelo, isso evita que haja sobreajustes, fará bom uso do one-hot encoding. \n",
    "\n",
    "Conforme visto no Nanodegree e no artigo https://dzone.com/articles/decision-trees-vs-clustering-algorithms-vs-linear de 2017, do autor Parikshit Joshi.\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "* Muito usado para classificação de texto, pode ser usado para prevenção de suicídio analisando postagens em redes sociais.\n",
    "* Uma grande vantagem é o fato do modelo considerar eventos passados, usando recursos de probabilidade estatística. Além de que o modelo é simples e com boa performance para predição.\n",
    "* Uma desvantagem é que o modelo trabalha muito melhor com variáveis discretas que continuas, e tendemos a jogar fora muita informação útil ao adaptar valores para essa realidade.\n",
    "* Devido a termos usado a estratégia one-hot encoding, muitas variáveis discretas podem fazer um bom uso do modelo. Já que a junção dessas características é o que parece trazer uma maior remuneração, isso é muito adequado para o modelo.\n",
    "\n",
    "De acordo com o conteúdo do Nanodegree e o artigo http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/ de 2011, do autor Edwin Chen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Criando um Pipeline de Treinamento e Predição\n",
    "Para avaliar adequadamente a performance de cada um dos modelos que você escolheu é importante que você crie um pipeline de treinamento e predição que te permite de maneira rápida e eficiente treinar os modelos utilizando vários tamanhos de conjuntos de dados para treinamento, além de performar predições nos dados de teste. Sua implementação aqui será utilizada na próxima seção. No bloco de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar `fbeta_score` e `accuracy_score` de [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    " - Adapte o algoritmo para os dados de treinamento e registre o tempo de treinamento. \n",
    " - Realize predições nos dados de teste `X_test`, e também nos 300 primeiros pontos de treinamento `X_train[:300]`.\n",
    "   - Registre o tempo total de predição. \n",
    " - Calcule a acurácia tanto para o conjundo de dados de treino quanto para o conjunto de testes.\n",
    " - Calcule o F-score para os dois conjuntos de dados: treino e testes. \n",
    "   - Garanta que você configurou o parâmetro `beta`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = None\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = None\n",
    "        \n",
    "    # TODO: Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = None\n",
    "    predictions_train = None\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = None\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = None\n",
    "        \n",
    "    # TODO: Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = None\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = None\n",
    "        \n",
    "    # TODO: Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = None\n",
    "       \n",
    "    # Success\n",
    "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Validação inicial do modelo\n",
    "No código da célular, você precisará implementar o seguinte:\n",
    "- Importar os três modelos de aprendizado supervisionado que você escolheu na seção anterior \n",
    "- Inicializar os três modelos e armazená-los em `'clf_A'`, `'clf_B'`, e `'clf_C'`. \n",
    "  - Utilize um `'random_state'` para cada modelo que você utilizar, caso seja fornecido.\n",
    "  - **Nota:** Utilize as configurações padrão para cada modelo - você otimizará um modelo específico em uma seção posterior\n",
    "- Calcule o número de registros equivalentes à 1%, 10%, e 100% dos dados de treinamento.\n",
    "  - Armazene estes valores em `'samples_1'`, `'samples_10'`, e `'samples_100'` respectivamente.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo de sua escolha, a implementação abaixo pode demorar algum tempo para executar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importe os três modelos de aprendizado supervisionado da sklearn\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = None\n",
    "clf_B = None\n",
    "clf_C = None\n",
    "\n",
    "# TODO: Calcule o número de amostras para 1%, 10%, e 100% dos dados de treinamento\n",
    "# HINT: samples_100 é todo o conjunto de treinamento e.x.: len(y_train)\n",
    "# HINT: samples_10 é 10% de samples_100\n",
    "# HINT: samples_1 é 1% de samples_100\n",
    "samples_100 = None\n",
    "samples_10 = None\n",
    "samples_1 = None\n",
    "\n",
    "# Colete os resultados dos algoritmos de aprendizado\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "vs.evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Melhorando os resultados\n",
    "Nesta seção final, você irá escolher o melhor entre os três modelos de aprendizado supervisionado para utilizar nos dados dos estudantes. Você irá então realizar uma busca grid para otimização em todo o conjunto de dados de treino (`X_train` e `y_train`) fazendo o tuning de pelo menos um parâmetro para melhorar o F-score anterior do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o melhor modelo\n",
    "\n",
    "* Baseado na validação anterior, em um ou dois parágrafos explique para a *CharityML* qual dos três modelos você acredita ser o mais apropriado para a tarefa de identificar indivíduos com remuneração anual superior à \\$50,000.  \n",
    "\n",
    "** DICA: ** \n",
    "Analise o gráfico do canto inferior esquerdo da célula acima(a visualização criada através do comando `vs.evaluate(results, accuracy, fscore)`) e verifique o F score para o conjunto de testes quando 100% do conjunto de treino é utilizado. Qual modelo possui o maior score? Sua resposta deve abranger os seguintes pontos:\n",
    "* métricas - F score no conjunto de testes quando 100% dos dados de treino são utilizados, \n",
    "* tempo de predição/treinamento \n",
    "* a adequação do algoritmo para este cojunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 - Descrevendo o modelo nos termos de Layman\n",
    " \n",
    "* Em um ou dois parágrafos, explique para a *CharityML*, nos termos de layman, como o modelo final escolhido deveria funcionar. Garanta que você está descrevendo as principais vantagens do modelo, tais como o modo de treinar o modelo e como o modelo realiza a predição. Evite a utilização de jargões matemáticos avançados, como por exemplo a descrição de equações. \n",
    "\n",
    "** DICA: **\n",
    "\n",
    "Quando estiver explicando seu modelo, cite as fontes externas utilizadas, caso utilize alguma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Tuning do modelo\n",
    "Refine o modelo escolhido. Utilize uma busca grid (`GridSearchCV`) com pleo menos um parâmetro importante refinado com pelo menos 3 valores diferentes. Você precisará utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você precisará implementar o seguinte:\n",
    "- Importar [`sklearn.grid_search.GridSearchCV`](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Inicializar o classificador escolhido por você e armazená-lo em `clf`.\n",
    " - Configurar um `random_state` se houver um disponível para o mesmo estado que você configurou anteriormente.\n",
    "- Criar um dicionário dos parâmetros que você quer otimizar para o modelo escolhido.\n",
    " - Exemplo: `parâmetro = {'parâmetro' : [lista de valores]}`.\n",
    " - **Nota:** Evite otimizar o parâmetro `max_features` se este parâmetro estiver disponível! \n",
    "- Utilize `make_scorer` para criar um objeto de pontuação `fbeta_score` (com $\\beta = 0.5$).\n",
    "- Realize a busca gride no classificador `clf` utilizando o `'scorer'` e armazene-o na variável `grid_obj`.   \n",
    "- Adeque o objeto da busca grid aos dados de treino (`X_train`, `y_train`) e armazene em `grid_fit`.\n",
    "\n",
    "**Nota:** Dependendo do algoritmo escolhido e da lista de parâmetros, a implementação a seguir pode levar algum tempo para executar! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar 'GridSearchCV', 'make_scorer', e qualquer biblioteca necessária\n",
    "\n",
    "# TODO: Inicializar o classificador\n",
    "clf = None\n",
    "\n",
    "# TODO: Criar a lista de parâmetros que você quer otimizar, utilizando um dicionário, caso necessário.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = None\n",
    "\n",
    "# TODO: Criar um objeto fbeta_score utilizando make_scorer()\n",
    "scorer = None\n",
    "\n",
    "# TODO: Realizar uma busca grid no classificador utilizando o 'scorer' como o método de score no GridSearchCV() \n",
    "grid_obj = None\n",
    "\n",
    "# TODO: Adequar o objeto da busca grid como os dados para treinamento e encontrar os parâmetros ótimos utilizando fit() \n",
    "grid_fit = None\n",
    "\n",
    "# Recuperar o estimador\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Realizar predições utilizando o modelo não otimizado e modelar\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Reportar os scores de antes e de depois\n",
    "print \"Unoptimized model\\n------\"\n",
    "print \"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions))\n",
    "print \"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5))\n",
    "print \"\\nOptimized Model\\n------\"\n",
    "print \"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions))\n",
    "print \"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Validação final do modelo\n",
    "\n",
    "* Qual é a accuracy e o F-score do modelo otimizado utilizando os dados de testes?\n",
    "* Estes scores são melhores ou piores do que o modelo antes da otimização? \n",
    "* Como os resultados do modelo otimizado se comparam aos benchmarks do naive predictor que você encontrou na **Questão 1**?_\n",
    "\n",
    "**Nota:** Preencha a tabela abaixo com seus resultados e então responda as questões no campo **Resposta** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados:\n",
    "\n",
    "|     Metric     | Unoptimized Model | Optimized Model |\n",
    "| :------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score |                   |                 |\n",
    "| F-score        |                   |   EXAMPLE       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Importância dos atributos\n",
    "\n",
    "Uma tarefa importante quando realizamos aprendizado supervisionado em um conjunto de dados como os dados do censo que estudamos aqui é determinar quais atributos fornecem maior poder de predição. Focando no relacionamento entre alguns poucos atributos mais importantes e na label alvo nós simplificamos muito o nosso entendimento do fenômeno, que é a coisa mais importante a se fazer. No caso deste projeto, isso significa que nós queremos identificar um pequeno número de atributos que possuem maior chance de predizer se um indivíduo possui renda anual superior à \\$50,000.\n",
    "\n",
    "Escolha um classificador da scikit-learn (e.x.: adaboost, random forests) que possua o atributo `feature_importance_`, que é uma função que calcula o ranking de importância dos atributos de acordo com o classificador escolhido. Na próxima célula python ajuste este classificador para o conjunto de treinamento e utilize este atributo para determinar os 5 atributos mais importantes do conjunto de dados do censo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 6 - Observação da Relevância dos Atributos\n",
    "Quando **Exploramos os dados**, vimos que existem treze atributos disponíveis para cada registro nos dados do censo. Destes treze atributos, quais os 5 atributos que você acredita que são os mais importantes para predição e em que ordem você os ranquearia? Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação - Extraindo a importância do atributo\n",
    "Escolha um algoritmo de aprendizado supervisionado da `sciki-learn` que possui o atributo `feature_importance_` disponível. Este atributo é uma função que ranqueia a importância de cada atributo dos registros do conjunto de dados quando realizamos predições baseadas no algoritmo escolhido.\n",
    "\n",
    "Na célula de código abaixo, você precisará implementar o seguinte:\n",
    " - Importar um modelo de aprendizado supervisionado da sklearn se este for diferente dos três usados anteriormente. \n",
    " - Treinar o modelo supervisionado com todo o conjunto de treinamento.\n",
    " - Extrair a importância dos atributos utilizando `'.feature_importances_'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar um modelo de aprendizado supervisionado que tenha 'feature_importances_'\n",
    "\n",
    "\n",
    "# TODO: Treinar o modelo utilizando o conjunto de treinamento com .fit(X_train, y_train)\n",
    "model = None\n",
    "\n",
    "# TODO: Extrair a importância dos atributos utilizando .feature_importances_ \n",
    "importances = None\n",
    "\n",
    "# Plotar\n",
    "vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 7 - Extraindo importância dos atributos\n",
    "\n",
    "Observe a visualização criada acima que exibe os cinco atributos mais relevantes para predizer se um indivíduo possui remuneração igual ou superior à \\$50,000 por ano.\n",
    "\n",
    "* Como estes cinco atributos se comparam com os 5 atributos que você discutiu na **Questão 6**? \n",
    "* Se você estivesse próximo da mesma resposta, como esta visualização confirma o seu raciocínio? \n",
    "* Se você não estava próximo, por que você acha que estes atributos são mais relevantes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando atributos\n",
    "\n",
    "Como um modelo performa se nós só utilizamos um subconjunto de todos os atributos disponíveis nos dados? Com menos atributos necessários para treinar, a expectativa é que o treinamento e a predição sejam executados em um tempo muito menor — com o custo da redução nas métricas de performance. A partir da visualização acima, nós vemos que os cinco atributos mais importantes contribuem para mais de 50% da importância de **todos** os atributos presentes nos dados. Isto indica que nós podemos tentar *reduzir os atributos* e simplificar a informação necessária para o modelo aprender. O código abaixo utilizará o mesmo modelo otimizado que você encontrou anteriormente e treinará o modelo com o mesmo conjunto de dados de treinamento, porém apenas com *os cinco atributos mais importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a funcionalidade para clonar um modelo\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduzir a quantidade de atributos\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Treinar o melhor modelo encontrado com a busca grid anterior\n",
    "clf = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "# Fazer novas predições\n",
    "reduced_predictions = clf.predict(X_test_reduced)\n",
    "\n",
    "# Reportar os scores do modelo final utilizando as duas versões dos dados.\n",
    "print \"Final Model trained on full data\\n------\"\n",
    "print \"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions))\n",
    "print \"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5))\n",
    "print \"\\nFinal Model trained on reduced data\\n------\"\n",
    "print \"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions))\n",
    "print \"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, reduced_predictions, beta = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 8 - Efeitos da seleção de atributos\n",
    "\n",
    "* Como o F-score do modelo final e o accuracy score do conjunto de dados reduzido utilizando apenas cinco atributos se compara aos mesmos indicadores utilizando todos os atributos? \n",
    "* Se o tempo de treinamento é uma variável importante, você consideraria utilizar os dados enxutos como seu conjunto de treinamento? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você tenha concluído toda a implementação de código e respondido cada uma das questões acima, você poderá finalizar o seu trabalho exportando o iPython Notebook como um documento HTML. Você pode fazer isso utilizando o menu acima navegando para \n",
    "**File -> Download as -> HTML (.html)**. Inclua este documento junto do seu notebook como sua submissão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
